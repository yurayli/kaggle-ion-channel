{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-02T03:14:35.772560Z",
     "iopub.status.busy": "2020-11-02T03:14:35.771717Z",
     "iopub.status.idle": "2020-11-02T03:16:14.513154Z",
     "shell.execute_reply": "2020-11-02T03:16:14.511757Z"
    },
    "papermill": {
     "duration": 98.766996,
     "end_time": "2020-11-02T03:16:14.513304",
     "exception": false,
     "start_time": "2020-11-02T03:14:35.746308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install RAPIDS 0.15.0\n",
    "\n",
    "import sys\n",
    "!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:25.889271Z",
     "iopub.status.busy": "2020-11-02T03:16:25.888209Z",
     "iopub.status.idle": "2020-11-02T03:16:28.311067Z",
     "shell.execute_reply": "2020-11-02T03:16:28.310380Z"
    },
    "papermill": {
     "duration": 2.440183,
     "end_time": "2020-11-02T03:16:28.311203",
     "exception": false,
     "start_time": "2020-11-02T03:16:25.871020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUML version: 0.15.0\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import cudf\n",
    "\n",
    "print(\"CUML version:\", cuml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:28.342160Z",
     "iopub.status.busy": "2020-11-02T03:16:28.341145Z",
     "iopub.status.idle": "2020-11-02T03:16:28.362151Z",
     "shell.execute_reply": "2020-11-02T03:16:28.361470Z"
    },
    "papermill": {
     "duration": 0.040967,
     "end_time": "2020-11-02T03:16:28.362270",
     "exception": false,
     "start_time": "2020-11-02T03:16:28.321303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        if col!='open_channels':\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:28.399838Z",
     "iopub.status.busy": "2020-11-02T03:16:28.398810Z",
     "iopub.status.idle": "2020-11-02T03:16:28.420261Z",
     "shell.execute_reply": "2020-11-02T03:16:28.419700Z"
    },
    "papermill": {
     "duration": 0.048691,
     "end_time": "2020-11-02T03:16:28.420383",
     "exception": false,
     "start_time": "2020-11-02T03:16:28.371692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# signal processing features\n",
    "def calc_gradients(s, n_grads=4):\n",
    "    '''\n",
    "    Calculate gradients for a pandas series. Returns the same number of samples\n",
    "    '''\n",
    "    grads = pd.DataFrame()\n",
    "    \n",
    "    g = s.values\n",
    "    for i in range(n_grads):\n",
    "        g = np.gradient(g)\n",
    "        grads['grad_' + str(i+1)] = g\n",
    "        \n",
    "    return grads\n",
    "\n",
    "def calc_low_pass(s, n_filts=5):\n",
    "    '''\n",
    "    Applies low pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.3, n_filts)\n",
    "    \n",
    "    low_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='low')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return low_pass\n",
    "\n",
    "def calc_high_pass(s, n_filts=5):\n",
    "    '''\n",
    "    Applies high pass filters to the signal. Left delayed and no delayed\n",
    "    '''\n",
    "    wns = np.logspace(-2, -0.1, n_filts)\n",
    "    \n",
    "    high_pass = pd.DataFrame()\n",
    "    x = s.values\n",
    "    for wn in wns:\n",
    "        b, a = signal.butter(1, Wn=wn, btype='high')\n",
    "        zi = signal.lfilter_zi(b, a)\n",
    "        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n",
    "        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n",
    "        \n",
    "    return high_pass\n",
    "\n",
    "def calc_ewm(s, windows=[10, 100]):\n",
    "    '''\n",
    "    Calculates exponential weighted functions\n",
    "    '''\n",
    "    ewm = pd.DataFrame()\n",
    "    for w in windows:\n",
    "        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n",
    "        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n",
    "        \n",
    "    # add zeros when na values (std)\n",
    "    ewm = ewm.fillna(value=0)\n",
    "        \n",
    "    return ewm\n",
    "\n",
    "def calc_signal_features(s):\n",
    "    '''\n",
    "    All calculations together\n",
    "    '''\n",
    "    low_pass = calc_low_pass(s)\n",
    "    high_pass = calc_high_pass(s)\n",
    "    ewm = calc_ewm(s)\n",
    "    \n",
    "    return pd.concat([s, low_pass, high_pass, ewm], axis=1)\n",
    "\n",
    "def signal_features(s, signal_size=500000):\n",
    "    '''\n",
    "    Divide the signal in bags of \"signal_size\".\n",
    "    Normalize the data dividing it by 15.0\n",
    "    '''\n",
    "    # normalize\n",
    "    s = s / 15.0\n",
    "    \n",
    "    ls = []\n",
    "    for i in range(s.shape[0]//signal_size):\n",
    "        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n",
    "        sig_featured = calc_signal_features(sig)\n",
    "        ls.append(sig_featured)\n",
    "    \n",
    "    ls = pd.concat(ls, axis=0)\n",
    "    return ls[ls.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:28.471751Z",
     "iopub.status.busy": "2020-11-02T03:16:28.466252Z",
     "iopub.status.idle": "2020-11-02T03:16:28.476531Z",
     "shell.execute_reply": "2020-11-02T03:16:28.476012Z"
    },
    "papermill": {
     "duration": 0.046942,
     "end_time": "2020-11-02T03:16:28.476643",
     "exception": false,
     "start_time": "2020-11-02T03:16:28.429701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rolling and aggreagate batch features\n",
    "def rolling_features(df):\n",
    "    for window in [10, 100]:\n",
    "        # rolling\n",
    "        df['mean_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).mean())\n",
    "        df['std_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).std())\n",
    "        df['var_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).var())\n",
    "        df['q25_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).quantile(0.25))\n",
    "        df['q50_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).quantile(0.50))\n",
    "        df['q75_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).quantile(0.75))\n",
    "        df['min_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).min())\n",
    "        df['max_t' + str(window)] = df.groupby(['group'])['signal'].transform(lambda x: x.rolling(window).max())\n",
    "        min_max = (df['signal'] - df['min_t' + str(window)]) / (df['max_t' + str(window)] - df['min_t' + str(window)])\n",
    "        df['norm_t' + str(window)] = min_max * (np.floor(df['max_t' + str(window)]) - np.ceil(df['min_t' + str(window)]))\n",
    "    return df.fillna(0)\n",
    "\n",
    "def shifted_features(df, num_shift=5):\n",
    "    steps = np.arange(1, num_shift+1, dtype=np.int32)\n",
    "    steps = np.append(steps, -steps)\n",
    "    for step in steps:\n",
    "        df['signal_shift_' + str(step)] = df['signal'].shift(step, fill_value=-2.73).astype( np.float32 )\n",
    "    return df\n",
    "\n",
    "def add_category(df):\n",
    "    # treat 10 open channels group as another category\n",
    "    df[\"category\"] = 0\n",
    "    if df.shape[0] > 2_000_000:\n",
    "        # train segments with more then 9 open channels classes\n",
    "        df.loc[2_000_000:2_500_000, 'category'] = 1\n",
    "        df.loc[4_500_000:5_000_000, 'category'] = 1\n",
    "    else:\n",
    "        # test segments with more then 9 open channels classes (potentially)\n",
    "        df.loc[500_000:600_000-1, \"category\"] = 1\n",
    "        df.loc[700_000:800_000-1, \"category\"] = 1\n",
    "    return df\n",
    "\n",
    "def add_features(df):\n",
    "    df = shifted_features(df)\n",
    "    df = rolling_features(df)\n",
    "    df = add_category(df)\n",
    "    df['signal_2'] = (df['signal'] ** 2)\n",
    "    df = reduce_mem_usage(df).reset_index(drop=True)\n",
    "    sg_df = signal_features(df['signal'])\n",
    "    sg_df = reduce_mem_usage(sg_df).reset_index(drop=True)\n",
    "    return pd.concat([df, sg_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:28.509190Z",
     "iopub.status.busy": "2020-11-02T03:16:28.508322Z",
     "iopub.status.idle": "2020-11-02T03:16:28.511953Z",
     "shell.execute_reply": "2020-11-02T03:16:28.512689Z"
    },
    "papermill": {
     "duration": 0.027031,
     "end_time": "2020-11-02T03:16:28.512848",
     "exception": false,
     "start_time": "2020-11-02T03:16:28.485817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv(\"../input/ion-clean/train_full_clean.csv\")\n",
    "    test = pd.read_csv(\"../input/ion-clean/test_full_clean.csv\")\n",
    "    sub = pd.read_csv(\"../input/liverpool-ion-switching/sample_submission.csv\")\n",
    "    train['signal'] = train['signal'].astype( np.float32 )\n",
    "    train['open_channels'] = train['open_channels'].astype( np.float32 )\n",
    "    test['signal'] = test['signal'].astype( np.float32 )\n",
    "    return train, test, sub\n",
    "\n",
    "def augment_data(df):\n",
    "    aug_df = df[df[\"group\"] == 5].copy()\n",
    "    aug_df[\"category\"] = 1\n",
    "    aug_df[\"group\"] = 10\n",
    "    for col in [\"signal\", \"open_channels\"]:\n",
    "        aug_df[col] += df[df[\"group\"] == 8][col].values\n",
    "\n",
    "    aug_df['category'] = aug_df['category'].astype( np.float32 )\n",
    "    df = df.append(aug_df, sort=False)\n",
    "    return df\n",
    "\n",
    "def drop_columns(df, columns=('open_channels', 'time', 'group')):\n",
    "    return df[[c for c in df.columns if c not in columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:16:28.550114Z",
     "iopub.status.busy": "2020-11-02T03:16:28.549106Z",
     "iopub.status.idle": "2020-11-02T03:19:55.594474Z",
     "shell.execute_reply": "2020-11-02T03:19:55.593849Z"
    },
    "papermill": {
     "duration": 207.072208,
     "end_time": "2020-11-02T03:19:55.594662",
     "exception": false,
     "start_time": "2020-11-02T03:16:28.522454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 324.25 Mb (54.1% reduction)\n",
      "Mem. usage decreased to 267.03 Mb (72.0% reduction)\n",
      "Mem. usage decreased to 122.07 Mb (55.6% reduction)\n",
      "Mem. usage decreased to 106.81 Mb (72.0% reduction)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "train, test, sub = load_data()\n",
    "train[\"group\"] = np.arange(train.shape[0]) // 500_000\n",
    "test[\"group\"] = np.arange(test.shape[0]) // 100_000\n",
    "\n",
    "train = add_features(train)\n",
    "test = drop_columns(add_features(test)).values.astype( np.float32 )\n",
    "train = augment_data(train)\n",
    "\n",
    "oof_preds = np.zeros((len(train)))\n",
    "pred_test = np.zeros((len(test)))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (trn_ind, val_ind) in enumerate(kf.split(train, train[\"group\"])):\n",
    "    print(f'Fold {fold}')\n",
    "    \n",
    "    trn, val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "    x_trn = drop_columns(trn).values.astype( np.float32 )\n",
    "    x_val = drop_columns(val).values.astype( np.float32 )\n",
    "    \n",
    "    model = RandomForestClassifier( #RandomForestRegressor\n",
    "            n_estimators=50,\n",
    "            rows_sample = 0.4,\n",
    "            max_depth=18,\n",
    "            max_features=11,        \n",
    "            split_algo=0,\n",
    "            bootstrap=False, #Don't use repeated rows, this is important to set to False to improve accuracy\n",
    "        ).fit( x_trn, trn.open_channels )\n",
    "    \n",
    "    pred_val = model.predict( x_val )\n",
    "    oof_preds[val_ind] = pred_val  # np.round( pred_val )\n",
    "        \n",
    "    pred_test += model.predict( test ) / 5\n",
    "    del model; _=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:19:55.628754Z",
     "iopub.status.busy": "2020-11-02T03:19:55.627581Z",
     "iopub.status.idle": "2020-11-02T03:19:58.583849Z",
     "shell.execute_reply": "2020-11-02T03:19:58.585076Z"
    },
    "papermill": {
     "duration": 2.976406,
     "end_time": "2020-11-02T03:19:58.585286",
     "exception": false,
     "start_time": "2020-11-02T03:19:55.608880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9426307262293996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(train.open_channels, oof_preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T03:19:58.640173Z",
     "iopub.status.busy": "2020-11-02T03:19:58.638925Z",
     "iopub.status.idle": "2020-11-02T03:20:07.738271Z",
     "shell.execute_reply": "2020-11-02T03:20:07.737358Z"
    },
    "papermill": {
     "duration": 9.133232,
     "end_time": "2020-11-02T03:20:07.738411",
     "exception": false,
     "start_time": "2020-11-02T03:19:58.605179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.open_channels = np.round( pred_test ).astype(np.int32)\n",
    "sub.to_csv(\"submission.csv\", index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 338.043065,
   "end_time": "2020-11-02T03:20:09.179413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-02T03:14:31.136348",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
